<h1>Compare Activation Function</h1>

<p>
<img src="readme/log.png"></br>
The log of training process.</br>
Two(Accuracy and Cross entropy loss) from the left.</br>
ReLU, Sigmoid, ReLU with He initialization.</br>
</p>

<p>
<img src="readme/R_VS_S_Loss.png"></br>
The loss graph of ReLU and Sigmoid.</br>
</p>

<p>
<img src="readme/R_VS_H_Loss.png"></br>
The loss graph of ReLU with He initialization and without.</br>
</p>
